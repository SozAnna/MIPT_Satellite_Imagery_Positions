{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3245acf6",
   "metadata": {},
   "source": [
    "# Привязка снимков к местности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0eab3b",
   "metadata": {},
   "source": [
    "Импортируем библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77fabe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from math import sin, cos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67edc57c",
   "metadata": {},
   "source": [
    "Создаем таблицу с ответами из файлов json для тренировочного датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fca6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = \"/train/json/\"\n",
    "\n",
    "\n",
    "data_df = pd.DataFrame({\"id\": [], \n",
    "                        \"left_top_x\": [], \"left_top_y\": [],\n",
    "                        \"right_top_x\": [], \"right_top_y\": [],\n",
    "                        \"left_bottom_x\": [], \"left_bottom_y\": [],\n",
    "                        \"right_bottom_x\": [], \"right_bottom_y\": [],\n",
    "                        \"angle\": []})\n",
    "\n",
    "json_true = []\n",
    "for _, _, files in os.walk(json_dir):\n",
    "    for x in files:\n",
    "        if x.endswith(\".json\"):\n",
    "            data = json.load(open(json_dir + x))\n",
    "            new_row = {\"id\": x.split(\".\")[0]+\".png\", \n",
    "                       \"left_top_x\":data[\"left_top\"][0], \"left_top_y\":data[\"left_top\"][1],\n",
    "                       \"right_top_x\":data[\"right_top\"][0], \"right_top_y\":data[\"right_top\"][1],\n",
    "                       \"left_bottom_x\": data[\"left_bottom\"][0], \"left_bottom_y\": data[\"left_bottom\"][1],\n",
    "                       \"right_bottom_x\": data[\"right_bottom\"][0], \"right_bottom_y\": data[\"right_bottom\"][1],\n",
    "                       \"angle\": data[\"angle\"]}\n",
    "            data_df = data_df.append(new_row, ignore_index=True)\n",
    "data_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68bd20e",
   "metadata": {},
   "source": [
    "Создадим два класса: для создания патчей из очень больших космических снимков, чтобы расширить тренировочный набор данных, и для составления собственно датасета из тренировочных данных. \n",
    "\n",
    "Для обучения модели вместо 8 координат 4 углов изображения будет использоваться только одна пара координат центра патча, что позволит облегчить процесс обучения модели за счет уменьшения количества предсказываемых параметров: их останется 3 (координаты центра и угол поворота). Поскольку нам известна форма патчей (квадрат) и их размер (1024 на 1024), мы сможем восстановить координаты углов по ответам модели.\n",
    "\n",
    "В генератор датасета также вшито вычисление координат центра патча."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3d1aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patcher(Dataset):\n",
    "    def __init__(self, path, transform, base_size, seed=42):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        self.imgs = []\n",
    "        for img_name in os.listdir(path):\n",
    "            self.imgs.append(Image.open(path + img_name).resize((base_size // 4, base_size // 4)))\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "\n",
    "    def crop(self, img, center_x, center_y, size):\n",
    "        left = center_x - size / 2\n",
    "        top = center_y - size / 2\n",
    "        right = center_x + size / 2\n",
    "        bottom = center_y + size / 2\n",
    "        return img.crop((left, top, right, bottom))\n",
    "\n",
    "    def __getitem__(self, indx):\n",
    "        img = self.imgs[self.rng.randint(0, len(self.imgs))]\n",
    "        x_center = self.rng.randint(512, base_size - 512)\n",
    "        y_center = self.rng.randint(512, base_size - 512)\n",
    "        angle = self.rng.randint(0, 360)\n",
    "\n",
    "        cropped = self.crop(img, x_center // 4, y_center // 4, 1024 * 3 // 2 // 4)\n",
    "        rotated = cropped.rotate(angle)\n",
    "        fixed_size = self.crop(rotated, 1024 * 3 // 4 // 4, 1024 * 3 // 4 // 4, 1024 // 4)\n",
    "        return self.transform(fixed_size), torch.tensor(np.array([x_center / base_size, y_center / base_size, angle / 360])).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return 10000\n",
    "\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, path, transform):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        self.imgs = []\n",
    "        for name in tqdm(df['id'].values):\n",
    "            self.imgs.append(self.transform(Image.open(f'{path}{name}').resize((1024 // 4, 1024 // 4))))\n",
    "        xs = ['left_top_x', 'right_top_x', 'right_bottom_x', 'left_bottom_x']\n",
    "        ys = ['left_top_y', 'right_top_y', 'right_bottom_y', 'left_bottom_y']\n",
    "        self.x_centers = (df[xs].max(axis=1) + df[xs].min(axis=1)) / 2 / base_size\n",
    "        self.y_centers = (df[ys].max(axis=1) + df[ys].min(axis=1)) / 2 / base_size\n",
    "        self.angles = df['angle'].values\n",
    "\n",
    "    def __getitem__(self, indx):\n",
    "        return self.imgs[indx], torch.tensor(np.array([self.x_centers[indx], self.y_centers[indx], self.angles[indx] / 360])).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782bbfcb",
   "metadata": {},
   "source": [
    "Задаем трансформации. Мы не можем менять геометрию изображений, поэтому не будем добавлять различные афинные преобразования. Но мы можем немного менять контраст изображения и размывать его блюром. Зачем? Возможно, это может немного сымитировать дымчатые снимки (со слабой облачностью). \n",
    "\n",
    "Для моделей, которые уже есть внутри Pytorch, размер изображений должен быть не менее 224 по одной из сторон, а также они должны были нормированы определенным образом. Эти значения приведены на сайте Pytorch. Несмотря на то, что патчи изначально немаленькие (со стороной 1024), визуальный анализ показывает, что уменьшение их в 4 раза (до 256) не приводит к потере значимой информации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b3153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomAutocontrast(p=0.3),\n",
    "    transforms.GaussianBlur(kernel_size=(3,3), sigma=(0.01, 2.0)),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize(256),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                          std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6935fc6",
   "metadata": {},
   "source": [
    "Чтобы увеличить объем тренировочных данных, при помощи ПО SAS.Planet были выгружены мозаики спутниковых снимков сверхвыского разрешения (того же размера, охвата и в той же проекции, что и оригинальное изображение), представленные в поисковых системах Google, Yandex, Bing, а также в Here, Mapbox, Esri. Поскольку все они безоблачные, а и тренировочные, и тестовые данные имеют облачные патчи, в Photoshop на некоторые из изображений были добавлены фейковые облака.\n",
    "Кроме того, у нас есть оригинальное изображение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80789b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_size = 10496 # Height of the original and other big images\n",
    "base_path = \"/bigs/\" # big images\n",
    "img_dir = \"/train/img/\" # train images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed30cae",
   "metadata": {},
   "source": [
    "На основе нарезки на патчи больших изображений создается тренировочный датасет. На основе тренировочных из задачи — валидационный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Patcher(base_path, train_transform, base_size)\n",
    "valid_dataset = ImageDataset(data_df, img_dir, valid_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a168401d",
   "metadata": {},
   "source": [
    "На их основе подготовим лоадеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd08714",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=25,\n",
    "                          shuffle=True)\n",
    "\n",
    "valid_loader = DataLoader(dataset=valid_dataset,\n",
    "                          batch_size=25,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8757ef31",
   "metadata": {},
   "source": [
    "Зададим функцию построения графика обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68125407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    plt.figure()\n",
    "    plt.title('{}'.format(title))\n",
    "    plt.plot(train_history, label='train', zorder=1)\n",
    "    \n",
    "    points = np.array(val_history)\n",
    "    steps = list(range(0, len(train_history) + 1, int(len(train_history) / len(val_history))))[1:]\n",
    "    \n",
    "    plt.scatter(steps, val_history, marker='x', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.xlabel('train steps')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5519445a",
   "metadata": {},
   "source": [
    "Также определим функцию вычисления метрики на основе той, что описана в тексте задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a17fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss(output, target):\n",
    "    pos_err = (torch.abs(target[:,0] - output[:,0]) + torch.abs(target[:,1] - output[:,1])) / 2\n",
    "    ang_diff = torch.abs(target[:,2] - output[:,2])\n",
    "    ang_err = torch.minimum(ang_diff, 1 - ang_diff)\n",
    "\n",
    "    loss = torch.mean(0.7 * pos_err + 0.3 * ang_err)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67013cd",
   "metadata": {},
   "source": [
    "Напишем функцию обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd217861",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7580b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_loader, val_loader, epochs=50):\n",
    "    train_loss_log = []\n",
    "    val_loss_log = []  \n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        train_loss = 0\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(imgs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            train_loss_log.append(loss.data.cpu().detach().numpy())\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "        val_loss = 0\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in val_loader:\n",
    "                \n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                pred = model(imgs)\n",
    "                loss = criterion(pred, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss_log.append(val_loss)\n",
    "\n",
    "        clear_output()\n",
    "        plot_history(train_loss_log, val_loss_log, 'loss')\n",
    "\n",
    "        print('Train loss:', train_loss / len(train_loader))\n",
    "        print('Val loss:', val_loss / len(val_loader))\n",
    "        \n",
    "    return train_loss_log, val_loss_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fcb994",
   "metadata": {},
   "source": [
    "Подгружаем модель. Здесь будет использоваться модель ResNet50 с предобученными весами и измененным выходным слоем, поскольку нам нужно 3 предсказания. Данная модель представляет собой сверточную нейронную сеть, отличительной особенностью которой является наличие остаточных слоев.\n",
    "\n",
    "В качестве функции потерь используется описанная выше функция на основе метрики из задачи, учитывающая ошибку в определении центра патча и угла его поворота. \n",
    "\n",
    "В качестве оптимизатора выбран адаптивный метод Adam, как один из самых эффективных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c8d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available()) # check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d743a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "model.fc = torch.nn.Sequential(torch.nn.Linear(2048, 3), torch.nn.Sigmoid())\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = my_loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b06047",
   "metadata": {},
   "source": [
    "Обучение модели на описанных ранее данных в течение 50 эпох."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74a2394",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_log, val_loss_log = train(model, \n",
    "                                     criterion,\n",
    "                                     optimizer, \n",
    "                                     train_loader, \n",
    "                                     valid_loader,\n",
    "                                     50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59189f5e",
   "metadata": {},
   "source": [
    "Далее дообучим модель на собственно тренировочных данных. Они не участвовали до этого момента в обучении модели.\n",
    "\n",
    "Для обучения датасет, который до этого был валидационным, придется разделить на тренировочный и валидационный. Определим долю последнего как 10 %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d818288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(valid_dataset))\n",
    "test_size = len(valid_dataset) - train_size\n",
    "train_set, val_set = torch.utils.data.random_split(valid_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b8acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_loader = DataLoader(dataset=train_set,\n",
    "                          batch_size=25,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(dataset=val_set,\n",
    "                          batch_size=25,\n",
    "                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908aff69",
   "metadata": {},
   "source": [
    "Продолжим обучение модели. Вновь на 50 эпохах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6ce055",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_log, val_loss_log = train(model, \n",
    "                                     criterion, \n",
    "                                     optimizer, \n",
    "                                     tr_loader, \n",
    "                                     val_loader,\n",
    "                                     50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146cc444",
   "metadata": {},
   "source": [
    "Итак, следующий шаг — финальный. Оценка тестового набора данных силами обученной выше модели. Однако напомним, что модель предсказывает не те ответы, которые нужны на выходе, поэтому их еще нужно преобразовать, вычислив на основе имеющихся данных координаты углов изображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eae496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_x(x, y, angle): # x coordinate after rotation\n",
    "    angle = angle * np.pi / 180 # from degrees to radians\n",
    "    return x * np.cos(angle) - y * np.sin(angle)\n",
    "\n",
    "def new_y(x, y, angle): # y coordinate after rotation\n",
    "    angle = angle * np.pi / 180 \n",
    "    return x * np.sin(angle) + y * np.cos(angle)\n",
    "\n",
    "# size of a patch = 1024. Half size = 512\n",
    "# if central point has coordinates (0, 0) and angle = 0...\n",
    "left_top_x = -512\n",
    "left_top_y = -512\n",
    "right_top_x = 512\n",
    "right_top_y = -512\n",
    "left_bottom_x = -512\n",
    "left_bottom_y = 512\n",
    "right_bottom_x = 512\n",
    "right_bottom_y = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2fb2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_dir = '/test_dataset_test/'\n",
    "f_names = os.listdir(test_images_dir)\n",
    "\n",
    "sub_dir = \"/submission/\"\n",
    "if not os.path.exists(sub_dir):\n",
    "    os.makedirs(sub_dir)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for name in f_names:\n",
    "    with open(f'{sub_dir}{name[:-4]}.json', 'w') as f:\n",
    "        img = valid_transform(Image.open(f'{test_images_dir}{name}').resize((1024 // 4, 1024 // 4)))\n",
    "        res = model(img.to(device).unsqueeze(0))\n",
    "        res = res.cpu().detach().numpy()[0]\n",
    "        res_coords = res[:2] * base_size\n",
    "        res_ang = res[2] * 360\n",
    "        const_pred = {\"left_top\": [round(new_x(left_top_x, left_top_y, res_ang) + res_coords[0]), \n",
    "                                   round(new_y(left_top_x, left_top_y, res_ang) + res_coords[1])], \n",
    "                      \"right_top\": [round(new_x(right_top_x, right_top_y, res_ang) + res_coords[0]), \n",
    "                                    round(new_y(right_top_x, right_top_y, res_ang) + res_coords[1])],\n",
    "                      \"left_bottom\": [round(new_x(left_bottom_x, left_bottom_y, res_ang) + res_coords[0]), \n",
    "                                      round(new_y(left_bottom_x, left_bottom_y, res_ang) + res_coords[1])], \n",
    "                      \"right_bottom\": [round(new_x(right_bottom_x, right_bottom_y, res_ang) + res_coords[0]), \n",
    "                                       round(new_y(right_bottom_x, right_bottom_y, res_ang) + res_coords[1])],\n",
    "                      \"angle\": round(res_ang)}\n",
    "        json.dump(const_pred, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
